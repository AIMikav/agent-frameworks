from pydantic_ai import Agent, Tool
from pydantic_ai.messages import ToolCallPart, ToolReturnPart
from pydantic_ai.models.openai import OpenAIModel
from dotenv import load_dotenv
import random
import json
import os

load_dotenv()

## Model

model = OpenAIModel(
    model_name=os.getenv("MODEL_NAME"),
    base_url=os.getenv("BASE_URL"),
    api_key=os.getenv("API_KEY"),
)

### Tools


async def generate_random_number(max_value: int) -> int:
    return random.randint(0, max_value)


async def is_approved(score: int) -> str:
    return "Approved" if score > 50 else "Denied"


### Agents

scorer = Agent(
    model,
    system_prompt=("You use the generate_random_number function to generate a score."),
    tools=[Tool(generate_random_number)],
    model_settings={"temperature": 0.0},
)

approver = Agent(
    model,
    system_prompt=(
        "You're Job is to simply tell users their score from the chat history"
        "You must tell the user if they are approved or denied based ont the outcome of the"
        "is_approved function."
    ),
    tools=[Tool(is_approved)],
    model_settings={"temperature": 0.0},
)

# Tasks

score_description = "Tell the user their score."
score_expected_output = (
    "Must be a structured output in the following format: Score(value={score})"
)

approver_description = "Tell the user if they are approved or denied based on the score they received generated by scorer in the previous step."
approver_expected_output = "Must be a structured output in the following format : Approve(answer=str, score=int, reason=str)"


# Run

tool_usage = {}
running = True

# Run multi-agent system as a while loop to over come inconsistencies in tool usage.
# Check that the output of generate_random_number is the same as the input to is_approved before proceeding.
while running:
    score_results = scorer.run_sync(f"{score_description} \n {score_expected_output}")
    history = score_results.new_messages()

    approver_results = approver.run_sync(
        f"{approver_description} \n {approver_expected_output}", message_history=history
    )

    messages = approver_results.all_messages()
    
    # Validate Results
    for i in messages:
        if isinstance(i.parts[0], ToolReturnPart):
            if i.parts[0].tool_name == "generate_random_number":
                tool_usage[f"{i.parts[0].tool_name}_return"] = i.parts[0].content
        if isinstance(i.parts[0], ToolCallPart):
            if i.parts[0].tool_name == "is_approved":
                tool_usage[f"{i.parts[0].tool_name}_call"] = i.parts[0].args.args_json

    score_tool_output = tool_usage["generate_random_number_return"]
    try:
        approver_tool_input = json.loads(tool_usage["is_approved_call"])["score"]
    except KeyError:
        approver_tool_input = None
    print(tool_usage)
    if score_tool_output == approver_tool_input:
        running = False

print(approver_results.data)
